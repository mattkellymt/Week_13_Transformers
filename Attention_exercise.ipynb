{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13 Exercise - Transformers\n",
    "\n",
    "In this notebook, we will explore the creation of a Transformer Network for English to French translation.  Note that **Transformers are resource intensive and hard to train.** You will want to run these notebooks on a machine equipped with a GPU or on [Google Colab](http://colab.research.google.com).\n",
    "\n",
    "To begin, let's import a corpus of paired English and French text.  Additionally, we'll tokenize the words (i.e. create a dictionary for each vocabulary associating every word with an integer index).  There is no need to modify this cell, but have a look at what is contained in fr_to_ix (for example) and in enlines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\" \n",
    "\n",
    "with open('./french.txt', encoding=\"utf-8\") as file:\n",
    "    frvocab = file.read().lower()\n",
    "    frvocab = ''.join([i if ord(i) < 128 else ' ' for i in frvocab])\n",
    "    frlines = frvocab.split('\\n')\n",
    "frlines = [re.sub(r'[^\\w\\s\\']','',i).split() for i in frlines]\n",
    "frvocab = set(re.sub(r'[^\\w\\s\\']','',frvocab).replace('\\n',' ').split(' '))\n",
    "\n",
    "with open('./english.txt', encoding=\"utf-8\") as file:\n",
    "    envocab = file.read().lower()\n",
    "    envocab = ''.join([i if ord(i) < 128 else '' for i in envocab])\n",
    "    enlines = envocab.split('\\n')\n",
    "enlines = [re.sub(r'[^\\w\\s]','',i).split() for i in enlines]\n",
    "envocab = set(re.sub(r'[^\\w\\s]','',envocab).replace('\\n',' ').strip().split(' '))\n",
    "envocab.add('<pad>')\n",
    "envocab.add('<start>')\n",
    "envocab.add('<eos>')\n",
    "frvocab.add('<pad>')\n",
    "frvocab.add('<start>')\n",
    "frvocab.add('<eos>')\n",
    "fr_to_ix = {word: i for i, word in enumerate(frvocab)}\n",
    "en_to_ix = {word: i for i, word in enumerate(envocab)}\n",
    "ix_to_fr = {fr_to_ix[word]:word for word in frvocab}\n",
    "ix_to_en = {en_to_ix[word]:word for word in envocab}\n",
    "enmax = 0\n",
    "frmax = 16\n",
    "\n",
    "for i,w in enumerate(enlines):\n",
    "    temp = len(w)\n",
    "    if temp > enmax:\n",
    "        enmax = temp\n",
    "\n",
    "for i,w in enumerate(frlines):\n",
    "    temp = len(w)\n",
    "    if temp > frmax:\n",
    "        frmax = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a handful of helper functions that do things like\n",
    " - Tokenize an english string, run it through the transformer producing predictions, then convert back to a french string\n",
    " - Compare predicted and target output\n",
    " - Mask a string\n",
    " - Load paired english/french sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # Read in an english string\n",
    "    line = re.sub(r'[^\\w\\s]','',sentence).split()\n",
    "    # tokenize/pad for consistent sequence length\n",
    "    line = F.pad(torch.tensor([en_to_ix[w.lower()] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).unsqueeze(0).to(device)\n",
    "    # Create an array to hold the French sentence\n",
    "    target = torch.Tensor(1,frmax-1)\n",
    "    target = target.new_full((1,frmax-1),fr_to_ix['<pad>']).long().to(device)\n",
    "    # Start sentence with a <start> character\n",
    "    target[0,0] = fr_to_ix['<start>']\n",
    "    \n",
    "    src,trg = mask(line,target)\n",
    "    encoding = model.encode(line,src)\n",
    "    K,V = model.create_dec_KV(encoding)\n",
    "    for i in range(1,frmax-1):\n",
    "        test2 = model.decode(target,K,V,src,trg)\n",
    "        lastout = test2[0,i-1].argmax()\n",
    "        if lastout.item() == fr_to_ix['<eos>']:\n",
    "            break\n",
    "        target[0,i] = lastout\n",
    "        src,trg = mask(line,target)\n",
    "    translation = test2.argmax(2).squeeze(0)\n",
    "    translation_string = ''\n",
    "    for w in translation:\n",
    "        if ix_to_fr[w.item()] == '<eos>':\n",
    "            break\n",
    "        translation_string += ix_to_fr[w.item()] + ' '\n",
    "    return translation_string.strip()\n",
    "\n",
    "def compareoutput(preds,targetlist,loc=None):\n",
    "    # Compare model predictions with true translation\n",
    "    if loc is None:\n",
    "        loc = np.random.randint(len(preds))\n",
    "    predstr = ''\n",
    "    labelstr = ''\n",
    "    for i in range(len(preds[loc][0])):\n",
    "        if ix_to_fr[targetlist[loc][i+1].item()] == '<eos>':\n",
    "            break\n",
    "        predstr += ' '+ ix_to_fr[preds[loc][0][i].item()]\n",
    "        labelstr += ' ' + ix_to_fr[targetlist[loc][i+1].item()]\n",
    "    print(\"\\tOutput:\", predstr)\n",
    "    print(\"\\tTarget:\",labelstr)\n",
    "    \n",
    "class PositionalEncoder(nn.Module):\n",
    "    # Create a positional encoding generator\n",
    "    def __init__(self, d_model, max_seq_len = 58):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "            for i in range(1,d_model,2):\n",
    "                pe[pos, i] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "        pe = pe\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:seq_len], \\\n",
    "        requires_grad=False).to(device)\n",
    "        return x\n",
    "\n",
    "def mask(input_seq,target_seq):\n",
    "    input_msk = (input_seq != en_to_ix['<pad>']).unsqueeze(1)\n",
    "    target_msk = (target_seq != fr_to_ix['<pad>']).unsqueeze(1)\n",
    "    size = target_seq.size(1) # get seq_len for matrix\n",
    "    nopeak_mask = np.triu(np.ones((1, size, size)),k=1)\n",
    "    nopeak_mask = Variable(torch.from_numpy(nopeak_mask).to(device) == 0)\n",
    "    target_msk = target_msk & nopeak_mask\n",
    "    return input_msk,target_msk\n",
    "\n",
    "class custdata(Dataset):\n",
    "    # Create a custom dataset object to serve up paired english and french lines\n",
    "    def __init__(self,enlines,frlines):\n",
    "        self.data_len = len(enlines) \n",
    "        self.data = [F.pad(torch.tensor([en_to_ix[w] for w in line]),(0,enmax-len(line)),value = en_to_ix['<pad>']).to(device) for line in enlines]\n",
    "        self.labels = []\n",
    "        for line in frlines:\n",
    "            line = ['<start>',*line,'<eos>']\n",
    "            self.labels.append(F.pad(torch.tensor([fr_to_ix[w] for w in line]),(0,frmax-len(line)),value = fr_to_ix['<pad>']).to(device))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i],self.labels[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "The first task is to code a self-attention mechanism, which corresponds to implementing Eq. 1 in Vaswani.\n",
    "#### http://jalammar.github.io/illustrated-transformer/ is a great reference for most of the programming in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self_attention(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR Q, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wk = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR K, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wv = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR V, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scaler = np.sqrt(enc_dim)\n",
    "    \n",
    "    def QKV(self,x):\n",
    "        Q = self.wq(x)  #### TODO#### CALCULATE Q # Elementwise matrix-vector multiplcation\n",
    "        K = self.wk(x)  #### TODO#### CALCULATE K # Elementwise matrix-vector multiplcation\n",
    "        V = self.wv(x)  #### TODO#### CALCULATE V # Elementwise matrix-vector multiplcation\n",
    "        return Q,K,V\n",
    "    \n",
    "    def score(self,Q,K,V,mask):\n",
    "        # scores are the stuff that goes inside the softmax\n",
    "        scores = torch.bmm(Q, K.T.permute(2,0,1))/self.scaler ### TODO ### CALCULATE THE SCORES. !!!DONT TOUCH THE PERMUTE!!!\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = self.dropout(F.softmax(scores,-1)) \n",
    "        return torch.bmm(scores, V) ### TODO ### FINISH CALCULATING SELF ATTENTION\n",
    "    \n",
    "    def forward(self,x,mask=None):\n",
    "        Q,K,V = self.QKV(x)\n",
    "        return self.score(Q,K,V,mask)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to produce the \"special\" attention mechanism that takes keys and values from the encoder, but queries from the decoder.  This is very similar to the self-attention mechanism, except that there should be two inputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encdec_attention(nn.Module):\n",
    "    def __init__(self,dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(dim, dim) #### TODO#### WEIGHTS FOR Q, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wk = nn.Linear(dim, dim) #### TODO#### WEIGHTS FOR K, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wv = nn.Linear(dim, dim) #### TODO#### WEIGHTS FOR V, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.scaler = np.sqrt(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def Q(self,x):\n",
    "        return self.wq(x)\n",
    "    \n",
    "    def score(self,Q,K,V,mask):\n",
    "        scores = torch.bmm(Q, K.T.permute(2,0,1))/self.scaler ### TODO ### CALCULATE THE SCORES. !!!DONT TOUCH THE PERMUTE!!!\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = self.dropout(F.softmax(scores,-1)) \n",
    "        return torch.bmm(scores, V) ### TODO ### FINISH CALCULATING SELF ATTENTION\n",
    "    \n",
    "    def forward(self,x,K,V,mask):\n",
    "        # DB Note: I'm not sure that this signature is right.  Seems like we should be taking x from the\n",
    "        # decoder, as well as another argument (call it y?) from the encoder, then producing K,V,Q internally,\n",
    "        # just like in the self-attention scheme.  Otherwise, how are wk and wv being used here?  it looks like \n",
    "        # these parameters have been shifted over to the Transformer module's create_dec_KV method.\n",
    "        Q = self.Q(x)\n",
    "        out = self.score(Q,K,V,mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder and Decoder\n",
    "With the attention mechanisms coded, now we need to create encoder and decoder models. These correspond to the things inside the boxes in Figure 1 of Vaswani.  \n",
    "#### Fill in the forward passes of the encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module): # One encoder block. \n",
    "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.enc_dim = enc_dim\n",
    "        self.residual = nn.Linear(dim,enc_dim)\n",
    "        \n",
    "        self.attention = self_attention(dim,enc_dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(enc_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(enc_dim,enc_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(enc_dim)\n",
    "    \n",
    "    def forward(self,x,mask):  #### TODO #### SET UP FORWARD PASS OF ENCODER\n",
    "        attention = self.attention(x, mask)\n",
    "        if self.dim != self.enc_dim: ### DONT TOUCH, THIS IS TO HELP WITH THE RESIDUAL CONNECTION ###\n",
    "            x = self.residual(x)\n",
    "        add_normal = self.norm1(attention + x)\n",
    "        \n",
    "        feed_forward = self.linear(add_normal)\n",
    "        return self.norm2(attention + feed_forward)\n",
    "        \n",
    "class decoder(nn.Module): # One decoder block\n",
    "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.attention = self_attention(input_size,dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.EDattention = encdec_attention(dim,dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dim,dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self,x,k,v,enc_mask,dec_mask):#### TODO #### SET UP FORWARD PASS OF DECODER\n",
    "        attention = self.attention(x, dec_mask)\n",
    "        add_normal = self.norm1(attention + x)\n",
    "        \n",
    "        ed_attention = self.EDattention(add_normal, k, v, enc_mask)\n",
    "        add_normal = self.norm2(ed_attention + add_normal)\n",
    "        \n",
    "        feed_forward = self.linear(add_normal)\n",
    "        return self.norm3(feed_forward + add_normal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Build the transformer itself by hooking together encoders and decoders.  Note the word embedding layers that we are going to learn.  \n",
    "\n",
    "#### Add encoders and decoders to transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
    "        super().__init__()\n",
    "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
    "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
    "        \n",
    "        self.pe1 = PositionalEncoder(dim,enmax)\n",
    "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
    "        \n",
    "        self.encoders = []\n",
    "        num_encoders = 6 # The number of English encoder blocks.\n",
    "        \n",
    "        \"\"\"\n",
    "        There is a bug in this code. When I have more than one encoder or decoder block the only output I ever get is\n",
    "        <pad>, but the number of pads do match the number of target words. This took a long time to figure out. \n",
    "        \n",
    "        With only one block the translator works great. I haven't been able to figure out why multiple blocks always predict\n",
    "        the exact same index. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.encoders.append(encoder(dim, encoder_dim, enc_vocab_size)) #### TODO #### ADD DESIRED # OF ENCODERS TO SELF.ENCODERS\n",
    "        self.encoders = nn.ModuleList(self.encoders)\n",
    "        \n",
    "        self.decoders = []\n",
    "        num_decoders = num_encoders # The number of French decoder blocks.\n",
    "        self.decoders.append(decoder(encoder_dim, encoder_dim, dec_vocab_size)) #### TODO #### ADD DESIRED # OF DECODERS TO SELF.DECODERS\n",
    "        self.decoders = nn.ModuleList(self.decoders)\n",
    "        \n",
    "        self.final = nn.Sequential( # These are the output probabilities for our entire model.\n",
    "            nn.Linear(encoder_dim,dec_vocab_size),\n",
    "            nn.LogSoftmax(2)\n",
    "        )\n",
    "        \n",
    "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
    "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
    "    def create_dec_KV(self,z):\n",
    "        K = self.k(z)\n",
    "        V = self.v(z)\n",
    "        return K,V\n",
    "    \n",
    "    def encode(self,x,src):\n",
    "        x = self.embedding1(x) # Create the embedding for the English sentence\n",
    "        x = self.pe1(x) # Add positional encoding to each word vector.\n",
    "        for layer in self.encoders: # Iterate through each encoder block.\n",
    "            x = layer(x,src)\n",
    "        return x\n",
    "    \n",
    "    def decode(self,y,K,V,src,trg):\n",
    "        y = self.embedding2(y) # Create the embedding for the masked French sentence\n",
    "        y = self.pe2(y) # Add positional encoding to each word vector.\n",
    "        for layer in self.decoders: # Iterate through each decoder block.\n",
    "            y = layer(y,K,V,src,trg)\n",
    "        return self.final(y) # This is where we generate our output probabilities\n",
    "    \n",
    "    def forward(self,x,y,src,trg):\n",
    "        \n",
    "        x = self.encode(x,src) # English\n",
    "        K,V = self.create_dec_KV(x)\n",
    "        y = self.decode(y,K,V,src,trg) # French\n",
    "        \n",
    "        return y # Y is our output probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network.\n",
    "\n",
    "##### This will be slow to train and require a lot of resources. You can reduce the batch_size to lower the vram requirement, you can reduce \n",
    "##### the run time by lowering number_of_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUMBER_OF_LINES = 20000\n",
    "\n",
    "train = custdata(enlines[:NUMBER_OF_LINES],frlines[:NUMBER_OF_LINES])\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val = custdata(enlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000],frlines[NUMBER_OF_LINES:NUMBER_OF_LINES+1000])\n",
    "valloader = torch.utils.data.DataLoader(dataset=val, batch_size=1, shuffle=True, drop_last=False)\n",
    "test = custdata(enlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000],frlines[NUMBER_OF_LINES+1000:NUMBER_OF_LINES+2000])\n",
    "testloader = torch.utils.data.DataLoader(dataset=test, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  loss: 132.3340749144554\n",
      "\tOutput:  il <eos> <eos>\n",
      "\tTarget:  pourquoi r sistestu\n",
      "Epoch: 2  loss: 53.791667610406876\n",
      "\tOutput:  ne sommes pas maintenant\n",
      "\tTarget:  ne l'appelle pas maintenant\n",
      "Epoch: 3  loss: 44.72700518369675\n",
      "\tOutput:  tom <eos> ais\n",
      "\tTarget:  parlezvous fran ais\n",
      "Epoch: 4  loss: 39.13782036304474\n",
      "\tOutput:  l <eos> <eos>\n",
      "\tTarget:  rappelle tes chiens\n",
      "Epoch: 5  loss: 34.4669189453125\n",
      "\tOutput:  faismoi avec moi <eos> me <eos>\n",
      "\tTarget:  venez avec moi je vous prie\n",
      "Epoch: 6  loss: 30.566477313637733\n",
      "\tOutput:  ta voiture <eos> votre\n",
      "\tTarget:  votre femme est ici\n",
      "Epoch: 7  loss: 27.772555142641068\n",
      "\tOutput:  estu heureux l\n",
      "\tTarget:  estu heureux ici\n",
      "Epoch: 8  loss: 25.670064374804497\n",
      "\tOutput:  qui nouveau l'a <eos> id e\n",
      "\tTarget:  de qui tait cette id e\n",
      "Epoch: 9  loss: 24.378016129136086\n",
      "\tOutput:  vous tes tr <eos>\n",
      "\tTarget:  vous tes fort timides\n",
      "Epoch: 10  loss: 23.23633711785078\n",
      "\tOutput:  savezvous le crois\n",
      "\tTarget:  peuxtu le croire\n",
      "Epoch: 11  loss: 22.482985518872738\n",
      "\tOutput:  que maintenant <eos>\n",
      "\tTarget:  astu faim maintenant\n",
      "Epoch: 12  loss: 16.694353356957436\n",
      "\tOutput:  vous contente ici\n",
      "\tTarget:  tesvous heureux ici\n",
      "Epoch: 13  loss: 14.362006269395351\n",
      "\tOutput:  ne me pas de me\n",
      "\tTarget:  ne t'approche pas de moi\n",
      "Epoch: 14  loss: 13.401196472346783\n",
      "\tOutput:  que eu t <eos>\n",
      "\tTarget:  astu bient t fini\n",
      "Epoch: 15  loss: 12.717769928276539\n",
      "\tOutput:  vous tes tr s contrari <eos>\n",
      "\tTarget:  vous tes tr s contrari es\n",
      "Epoch: 16  loss: 12.229330569505692\n",
      "\tOutput:  vous le le fait\n",
      "\tTarget:  c'est toi l'a n\n",
      "Epoch: 17  loss: 11.75930367782712\n",
      "\tOutput:  ne marche pas si vite\n",
      "\tTarget:  ne marche pas si vite\n",
      "Epoch: 18  loss: 11.45218950882554\n",
      "\tOutput:  vous me fait un mal <eos>\n",
      "\tTarget:  tu as fait du mauvais travail\n",
      "Epoch: 19  loss: 11.145580649375916\n",
      "\tOutput:  les ons restent des\n",
      "\tTarget:  gar ons soyez ambitieux\n",
      "Epoch: 20  loss: 10.798726011067629\n",
      "\tOutput:  tesvous occup e\n",
      "\tTarget:  estu occup aujourd'hui\n",
      "Epoch: 21  loss: 10.611050765961409\n",
      "\tOutput:  ne le dites pas que ce soit\n",
      "\tTarget:  ne le dis qui que ce soit\n",
      "Epoch: 22  loss: 10.419458542019129\n",
      "\tOutput:  qui est votre p re\n",
      "\tTarget:  qui est ton p re\n",
      "Epoch: 23  loss: 9.44896887615323\n",
      "\tOutput:  qui ton vous <eos> fils\n",
      "\tTarget:  de qui estu le fils\n",
      "Epoch: 24  loss: 9.335561215877533\n",
      "\tOutput:  tu en avait assez assez\n",
      "\tTarget:  vous en avez eu assez\n",
      "Epoch: 25  loss: 9.256738159805536\n",
      "\tOutput:  pourquoi estce fait <eos>\n",
      "\tTarget:  pourquoi aije fait cela\n",
      "Epoch: 26  loss: 9.181767459958792\n",
      "\tOutput:  il devez besoin de sommeil\n",
      "\tTarget:  vous avez besoin de dormir\n",
      "Epoch: 27  loss: 9.122708685696125\n",
      "\tOutput:  vous tesvous tellement idiot\n",
      "\tTarget:  vous tes tellement idiotes\n",
      "Epoch: 28  loss: 9.090766854584217\n",
      "\tOutput:  tu n'es un bon <eos>\n",
      "\tTarget:  tu es un bon gamin\n",
      "Epoch: 29  loss: 8.999783173203468\n",
      "\tOutput:  faites un plan\n",
      "\tTarget:  avezvous un plan\n",
      "Epoch: 30  loss: 8.979065753519535\n",
      "\tOutput:  tout le monde y l\n",
      "\tTarget:  tout le monde tait l\n",
      "Epoch: 31  loss: 9.014395471662283\n",
      "\tOutput:  vous es tr s timide\n",
      "\tTarget:  tu es tr s craintif\n",
      "Epoch: 32  loss: 8.939682722091675\n",
      "\tOutput:  maman m me <eos> <eos> <eos>\n",
      "\tTarget:  ta m re estelle au courant\n",
      "Epoch: 33  loss: 8.885288704186678\n",
      "\tOutput:  tu\n",
      "\tTarget:  irastu\n",
      "Epoch: 34  loss: 8.867516800761223\n",
      "\tOutput:  vous le de plus\n",
      "\tTarget:  c'est toi l'a n\n",
      "Epoch: 35  loss: 8.839771147817373\n",
      "\tOutput:  ne ma pas <eos> femme\n",
      "\tTarget:  ne dites rien ma femme\n",
      "Epoch: 36  loss: 8.857123006135225\n",
      "\tOutput:  vous n' pas le choix\n",
      "\tTarget:  vous n'aviez pas le choix\n",
      "Epoch: 37  loss: 8.777842193841934\n",
      "\tOutput:  vous es le plus\n",
      "\tTarget:  tu es la doyenne\n",
      "Epoch: 38  loss: 8.749693255871534\n",
      "\tOutput:  gonflez tient <eos> le lu <eos>\n",
      "\tTarget:  d poussi rez l' tag re\n",
      "Epoch: 39  loss: 8.718649730086327\n",
      "\tOutput:  maintenant maintenant bien maintenant\n",
      "\tTarget:  tu vas mieux maintenant\n",
      "Epoch: 40  loss: 8.668757859617472\n",
      "\tOutput:  vous tes incroyables s\n",
      "\tTarget:  vous tes cern e\n",
      "Epoch: 41  loss: 8.638045649975538\n",
      "\tOutput:  vous es as semblant\n",
      "\tTarget:  tu me fais peur\n",
      "Epoch: 42  loss: 8.572367414832115\n",
      "\tOutput:  en en cong\n",
      "\tTarget:  estu en vacances\n",
      "Epoch: 43  loss: 8.601288415491581\n",
      "\tOutput:  tu as l'air de <eos>\n",
      "\tTarget:  tu as l'air europ en\n",
      "Epoch: 44  loss: 8.503704871982336\n",
      "\tOutput:  tesvous seul ici\n",
      "\tTarget:  estu seul ici\n",
      "Epoch: 45  loss: 8.454959824681282\n",
      "\tOutput:  vous le embrasser chirurgien\n",
      "\tTarget:  c'est vous le chef\n",
      "Epoch: 46  loss: 8.429291512817144\n",
      "\tOutput:  tout le monde s'est r en s curit\n",
      "\tTarget:  tout le monde s'est senti en s curit\n",
      "Epoch: 47  loss: 8.40915934741497\n",
      "\tOutput:  tu ne peux pas admettre te\n",
      "\tTarget:  tu ne peux pas arr ter\n",
      "Epoch: 48  loss: 8.384639877825975\n",
      "\tOutput:  sontils satisfaits <eos>\n",
      "\tTarget:  sontils content s\n",
      "Epoch: 49  loss: 8.320198863744736\n",
      "\tOutput:  les repas est en\n",
      "\tTarget:  les repas sontils inclus\n",
      "Epoch: 50  loss: 8.383099608123302\n",
      "\tOutput:  tout le monde l'aime\n",
      "\tTarget:  tout le monde l'aime\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for j,(context, target) in enumerate(trainloader): # j, (English, French)\n",
    "        # print(f\"Context Shape: {context.shape}, Target Shape: {target.shape}\")\n",
    "        trg_input = target[:,:-1]\n",
    "        outmask = target[:,1:]!= fr_to_ix['<pad>'] \n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg) # This is our output probabilities for our transformer.\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    scheduler.step(total_loss) # We are adjusting our learning rate here.\n",
    "    print('Epoch:', i+1,' loss:', total_loss)\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    preds = []\n",
    "    targetlist = []\n",
    "    for j,(context, target) in enumerate(valloader):\n",
    "            trg_input = target[:,:-1]\n",
    "            targets = target.contiguous().view(-1)\n",
    "            targetlist.append(targets)\n",
    "            src,trg = mask(context,trg_input)\n",
    "            output = model(context,trg_input,src,trg)\n",
    "            #print(f\"Test output: {output}\")\n",
    "            pred = F.softmax(output,2).argmax(2)\n",
    "            #print(f\"Test predictions: {pred}\")\n",
    "            preds.append(pred)\n",
    "            break\n",
    "    compareoutput(preds,targetlist,loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your translator\n",
    "\n",
    "##### Unless you speak french you're going have to check it with google translate https://translate.google.com/\n",
    "##### I found it started doing alright once the loss got below 10 but this might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comment va'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'how are you'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test it on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of words correct 0.5857700216450217\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "scores = []\n",
    "preds = []\n",
    "targetlist = []\n",
    "for j,(context, target) in enumerate(testloader):\n",
    "        trg_input = target[:,:-1]\n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        targetlist.append(targets)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg)\n",
    "        pred = F.softmax(output,2).argmax(2)\n",
    "        preds.append(pred)\n",
    "        correct = sum(pred[0][targets!=fr_to_ix['<pad>']]==targets[targets!=fr_to_ix['<pad>']]).item()/len(targets[targets!=fr_to_ix['<pad>']])\n",
    "        scores.append(correct)\n",
    "plt.plot(scores)\n",
    "print('Average # of words correct',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-HEAD ATTENTION (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_attention(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        \n",
    "        heads = []\n",
    "        num_heads = 6\n",
    "        for i in range(num_heads): ### TODO ### CHOOSE THE # OF HEADS YOU WANT\n",
    "            heads.append(self_attention(dim, encoder_dim, dropout)) ### TODO ### ADD SELF_ATTENTION LAYERS TO HEADS\n",
    "        \n",
    "        self.heads = nn.ModuleList(heads)\n",
    "        \n",
    "        self.linear = nn.Linear(dim,encoder_dim) ### TODO ###\n",
    "    \n",
    "    \n",
    "    def forward(self,x,mask=None):\n",
    "        headoutputs = [layer(x,mask) for layer in self.heads] # Shouldn't each word be mapped to a head? Maybe I'm misunderstanding.\n",
    "        # This looks like the same data is being mapped to the same layer many times. \n",
    "        headoutputs = torch.cat(headoutputs,dim=2)\n",
    "        return self.linear(headoutputs)\n",
    "\"\"\" For my reference\n",
    "class self_attention(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,dropout = .1):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR Q, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wk = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR K, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.wv = nn.Linear(dim, enc_dim) #### TODO#### WEIGHTS FOR V, INPUT DIM = DIM, OUTPUT DIM = ENC_DIM\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scaler = np.sqrt(enc_dim)\n",
    "    \n",
    "    def QKV(self,x):\n",
    "        Q = self.wq(x)  #### TODO#### CALCULATE Q # Elementwise matrix-vector multiplcation\n",
    "        K = self.wk(x)  #### TODO#### CALCULATE K # Elementwise matrix-vector multiplcation\n",
    "        V = self.wv(x)  #### TODO#### CALCULATE V # Elementwise matrix-vector multiplcation\n",
    "        return Q,K,V\n",
    "    \n",
    "    def score(self,Q,K,V,mask):\n",
    "        # scores are the stuff that goes inside the softmax\n",
    "        scores = torch.bmm(Q, K.T.permute(2,0,1))/self.scaler ### TODO ### CALCULATE THE SCORES. !!!DONT TOUCH THE PERMUTE!!!\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = self.dropout(F.softmax(scores,-1)) \n",
    "        return torch.bmm(scores, V) ### TODO ### FINISH CALCULATING SELF ATTENTION\n",
    "    \n",
    "    def forward(self,x,mask=None):\n",
    "        Q,K,V = self.QKV(x)\n",
    "        return self.score(Q,K,V,mask)\n",
    "\"\"\"    \n",
    "class encoder(nn.Module):\n",
    "    def __init__(self,dim,enc_dim,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.enc_dim = enc_dim\n",
    "        self.attention = multi_attention(dim,enc_dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(enc_dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(enc_dim,enc_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.residual = nn.Linear(dim,enc_dim)\n",
    "        self.norm2 = nn.LayerNorm(enc_dim)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        z = self.attention(x,mask)\n",
    "        if self.dim != self.enc_dim:\n",
    "            x = self.residual(x)\n",
    "        z = self.norm1(x+z)\n",
    "        z2 = self.linear(z)\n",
    "        return self.norm2(z+z2)\n",
    "     \n",
    "    \n",
    "class decoder(nn.Module):\n",
    "    def __init__(self,dim,input_size,vocab_size,dropout=.1):\n",
    "        super().__init__()\n",
    "        self.attention = multi_attention(input_size,dim,dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.EDattention = encdec_attention(dim,dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(dim,dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "    \n",
    "    def forward(self,x,k,v,src,trg):\n",
    "        z = self.attention(x,trg)\n",
    "        z = self.norm1(z+x)\n",
    "        z2 = self.EDattention(z,k,v,src)\n",
    "        z2 = self.norm2(z2+z)\n",
    "        z3 = self.linear(z2)\n",
    "        return self.norm3(z3+z2)\n",
    "    \n",
    "class transformer(nn.Module):\n",
    "    def __init__(self,dim,encoder_dim,enc_vocab_size,dec_vocab_size,input_size):\n",
    "        super().__init__()\n",
    "        self.embedding1 = nn.Embedding(enc_vocab_size,dim)\n",
    "        self.embedding2 = nn.Embedding(dec_vocab_size,encoder_dim)\n",
    "        \n",
    "        self.pe1 = PositionalEncoder(dim,enmax)\n",
    "        self.pe2 = PositionalEncoder(encoder_dim,frmax)\n",
    "        self.encoders = []\n",
    "    \n",
    "        self.encoders.append(encoder(dim,encoder_dim,enc_vocab_size))   ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
    "        self.encoders = nn.ModuleList(self.encoders)\n",
    "        \n",
    "        self.decoders = []\n",
    "        self.decoders.append(decoder(encoder_dim,encoder_dim,dec_vocab_size)) ### FEEL FREE TO ADD OR REMOVE ENCODERS\n",
    "        self.decoders = nn.ModuleList(self.decoders)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Linear(encoder_dim,dec_vocab_size),\n",
    "            nn.LogSoftmax(2)\n",
    "        )\n",
    "        \n",
    "        self.k = nn.Linear(encoder_dim,encoder_dim)\n",
    "        self.v = nn.Linear(encoder_dim,encoder_dim)\n",
    "        \n",
    "    def create_dec_KV(self,z):\n",
    "        K = self.k(z)\n",
    "        V = self.v(z)\n",
    "        return K,V\n",
    "    \n",
    "    def encode(self,x,src):\n",
    "        x = self.embedding1(x)\n",
    "        x = self.pe1(x)\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x,src)\n",
    "        return x\n",
    "\n",
    "    def decode(self,y,K,V,src,trg):\n",
    "        y = self.embedding2(y)\n",
    "        y = self.pe2(y)\n",
    "        for layer in self.decoders:\n",
    "            y = layer(y,K,V,src,trg)\n",
    "        return self.final(y)\n",
    "        \n",
    "    \n",
    "    def forward(self,x,y,src,trg):\n",
    "        x = self.encode(x,src)\n",
    "        K,V = self.create_dec_KV(x)\n",
    "        y = self.decode(y,K,V,src,trg)\n",
    "        \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(enmax,enmax,len(envocab),len(frvocab),frmax)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=.1,patience=10,threshold=1,min_lr=.0001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [5632 x 264], m2: [44 x 44] at C:/w/1/s/tmp_conda_3.7_100118/conda/conda-bld/pytorch_1579082551706/work/aten/src\\THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-838f1898fe67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-ad4f21e431b7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, src, trg)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dec_KV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-ad4f21e431b7>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, x, src)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpe1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-ad4f21e431b7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_dim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-234-ad4f21e431b7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mheadoutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mheadoutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadoutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadoutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \"\"\" For my reference\n\u001b[0;32m     20\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mself_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [5632 x 264], m2: [44 x 44] at C:/w/1/s/tmp_conda_3.7_100118/conda/conda-bld/pytorch_1579082551706/work/aten/src\\THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for j,(context, target) in enumerate(trainloader):\n",
    "        trg_input = target[:,:-1]\n",
    "        outmask = target[:,1:]!= fr_to_ix['<pad>']\n",
    "        targets = target[:,1:].contiguous().view(-1)\n",
    "        src,trg = mask(context,trg_input)\n",
    "        output = model(context,trg_input,src,trg)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.view(output.shape[0]*output.shape[1],-1),targets)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    scheduler.step(total_loss)\n",
    "    print('Epoch:', i+1,' loss:', total_loss)\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    preds = []\n",
    "    targetlist = []\n",
    "    for j,(context, target) in enumerate(valloader):\n",
    "            trg_input = target[:,:-1]\n",
    "            targets = target.contiguous().view(-1)\n",
    "            targetlist.append(targets)\n",
    "            src,trg = mask(context,trg_input)\n",
    "            output = model(context,trg_input,src,trg)\n",
    "            pred = F.softmax(output,2).argmax(2)\n",
    "            preds.append(pred)\n",
    "            break\n",
    "    compareoutput(preds,targetlist,loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your  multi-head transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'how are you'\n",
    "translate(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION\n",
    "\n",
    "#### 1) Was the runtime of your multi-head transformer noticably longer than the single head one? What about the speed the loss decreased? If you had the time and resources to train it to a good spot, how did the translation quality compare to the single-headed transformer?\n",
    "\n",
    "A: I was not able to get the multi-head transformer working. I thought that words were parallelized by distributing words to attention blocks. \n",
    "\n",
    "#### 2)Try adding encoders and decoders to one of your transformers. Does having the extra layers improve performance? How does it affect runtime?\n",
    "\n",
    "A: Adding more than 1 encoder or decoder block caused my output to always produce \"pad\" although the number of pads always matched the number of desired words. With a single decoder and a single encoder block I did produce a meaningful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
